# M4 — Eliminate Redundant Transposes

**Goal:** Implement the first high-impact structural pass. Build synthetic dirty ONNX models
that have exactly the problem we're fixing — cancelling Transpose pairs — so we can assert
the pass works precisely, not just "verify didn't blow up."

---

## New Testing Philosophy — Synthetic Dirty Models

From M4 onwards, every pass gets its own hand-crafted toy ONNX model that:
- Has exactly the pathological pattern the pass targets
- Is small enough to inspect node-by-node
- Lets you assert specific outcomes (e.g. "nodes went from 4 to 2")
- Lives in `tests/toy_models/` and is generated by a builder script

This means you never have to wonder "did the pass actually fire?" — the toy model
guarantees it has to.

```
onnxslim/
├── passes/
│   └── eliminate_redundant_transposes.py   ← NEW
├── tests/
│   ├── toy_models/
│   │   ├── __init__.py                     ← NEW (empty)
│   │   └── build_transpose_model.py        ← NEW — generates dirty ONNX models
│   ├── test_mobilenetv2.py                 ✅ done
│   └── test_transposes.py                  ← NEW — precise assertions on toy models
```

---

## Background — Why Redundant Transposes Exist

PyTorch stores tensors in NCHW (batch, channels, height, width).
TFLite and many mobile runtimes prefer NHWC (batch, height, width, channels).

When you export a PyTorch model to ONNX targeting mobile, the exporter inserts Transpose
ops to handle the layout difference. Sometimes it inserts pairs that cancel each other out:

```
input (NCHW)
    → Transpose(perm=[0,2,3,1])   # NCHW → NHWC
    → [some op]
    → Transpose(perm=[0,3,1,2])   # NHWC → NCHW  ← cancels the first one
    → output (NCHW)
```

These two Transposes compose to identity — the data comes out exactly as it went in.
They should be removed entirely.

Sometimes you also get chains that don't cancel but can be merged into one:

```
Transpose(perm=[0,2,1,3])
    → Transpose(perm=[0,1,3,2])
    → result is equivalent to a single Transpose(perm=[0,3,1,2])
```

Two ops → one op.

---

## Permutation Math

The key insight: composing two permutations is just index lookup.

```python
def compose_perms(p1, p2):
    """
    Apply p1 first, then p2.
    Result[i] = p1[p2[i]]

    Example:
        p1 = [0, 2, 3, 1]   # NCHW → NHWC
        p2 = [0, 3, 1, 2]   # NHWC → NCHW
        composed = [p1[p2[i]] for i in range(len(p2))]
                 = [p1[0], p1[3], p1[1], p1[2]]
                 = [0, 1, 2, 3]   ← identity! remove both
    """
    return [p1[p2[i]] for i in range(len(p2))]

def is_identity_perm(perm):
    return perm == list(range(len(perm)))
```

---

## Pass: `passes/eliminate_redundant_transposes.py`

### Algorithm

1. Build a map: `output_name → node` for every node in the graph
2. Scan for Transpose nodes whose output feeds directly into another Transpose node
3. Compose their permutations
4. If composed perm is identity → remove both, rewire input of first to output of second
5. If composed perm is not identity → replace both with a single Transpose using composed perm
6. Repeat until no more consecutive Transpose pairs exist (chains need multiple passes)

### Code

```python
import onnx
from onnx import helper
from passes.base_pass import BasePass


def _get_perm(node):
    """Extract perm attribute from a Transpose node as a list of ints."""
    for attr in node.attribute:
        if attr.name == "perm":
            return list(attr.ints)
    return None


def _compose_perms(p1, p2):
    """Compose two permutations: apply p1 first, then p2."""
    return [p1[p2[i]] for i in range(len(p2))]


def _is_identity_perm(perm):
    return perm == list(range(len(perm)))


def _make_transpose_node(input_name, output_name, perm, name):
    return helper.make_node(
        "Transpose",
        inputs=[input_name],
        outputs=[output_name],
        perm=perm,
        name=name,
    )


class EliminateRedundantTransposes(BasePass):

    @property
    def name(self) -> str:
        return "eliminate_redundant_transposes"

    def run(self, model: onnx.ModelProto) -> onnx.ModelProto:
        changed = True
        total_removed = 0

        while changed:
            model, removed = self._run_one_pass(model)
            total_removed += removed
            changed = removed > 0

        if total_removed > 0:
            print(f"    → eliminated {total_removed} redundant transpose(s)")

        return model

    def _run_one_pass(self, model: onnx.ModelProto):
        graph = model.graph
        nodes = list(graph.node)

        # Map: output_name → node (for fast lookup)
        output_to_node = {}
        for node in nodes:
            for out in node.output:
                output_to_node[out] = node

        # Graph output names — cannot remove nodes whose output is a graph output
        graph_output_names = {o.name for o in graph.output}

        nodes_to_remove = set()
        nodes_to_add = []
        rewire = {}  # old_output → new_output (for downstream rewiring)

        for node in nodes:
            if node.op_type != "Transpose":
                continue
            if id(node) in nodes_to_remove:
                continue

            # Does this Transpose feed into another Transpose?
            out = node.output[0]
            if out not in output_to_node:
                continue
            next_node = output_to_node[out]
            if next_node.op_type != "Transpose":
                continue
            if id(next_node) in nodes_to_remove:
                continue

            # Don't collapse if intermediate output is a graph output
            if out in graph_output_names:
                continue

            p1 = _get_perm(node)
            p2 = _get_perm(next_node)

            if p1 is None or p2 is None:
                continue

            composed = _compose_perms(p1, p2)

            if _is_identity_perm(composed):
                # Remove both — rewire input of first directly to output of second
                rewire[next_node.output[0]] = node.input[0]
                nodes_to_remove.add(id(node))
                nodes_to_remove.add(id(next_node))

            else:
                # Replace both with one composed Transpose
                new_node = _make_transpose_node(
                    input_name=node.input[0],
                    output_name=next_node.output[0],
                    perm=composed,
                    name=f"{node.name}_fused",
                )
                nodes_to_remove.add(id(node))
                nodes_to_remove.add(id(next_node))
                nodes_to_add.append(new_node)

        if not nodes_to_remove:
            return model, 0

        # Apply rewiring to all node inputs
        for n in graph.node:
            for i, inp in enumerate(n.input):
                if inp in rewire:
                    n.input[i] = rewire[inp]

        # Apply rewiring to graph outputs
        for out in graph.output:
            if out.name in rewire:
                out.name = rewire[out.name]

        # Rebuild node list
        new_nodes = [n for n in graph.node if id(n) not in nodes_to_remove]
        new_nodes.extend(nodes_to_add)

        del graph.node[:]
        graph.node.extend(new_nodes)

        return model, len(nodes_to_remove)
```

---

## Toy Model Builder: `tests/toy_models/build_transpose_model.py`

Builds four synthetic dirty ONNX models with known expected outcomes.

```python
"""
Builds synthetic dirty ONNX models for testing eliminate_redundant_transposes.
Run directly to regenerate: python tests/toy_models/build_transpose_model.py
"""
import os
import onnx
from onnx import helper, TensorProto


def build_cancelling_pair(output_path="tests/toy_models/transpose_cancelling.onnx"):
    """
    Two Transposes that cancel each other (compose to identity).
        input  (1,3,4,4) NCHW
        → Transpose(perm=[0,2,3,1])   NCHW → NHWC
        → Transpose(perm=[0,3,1,2])   NHWC → NCHW  ← cancels first
        → output (1,3,4,4)
    Expected: 2 nodes → 0 nodes
    """
    X = helper.make_tensor_value_info("X", TensorProto.FLOAT, [1, 3, 4, 4])
    Y = helper.make_tensor_value_info("Y", TensorProto.FLOAT, [1, 3, 4, 4])

    t1 = helper.make_node("Transpose", ["X"],   ["mid"], perm=[0, 2, 3, 1], name="T1")
    t2 = helper.make_node("Transpose", ["mid"], ["Y"],   perm=[0, 3, 1, 2], name="T2")

    graph = helper.make_graph([t1, t2], "cancelling_pair", [X], [Y])
    model = helper.make_model(graph, opset_imports=[helper.make_opsetid("", 13)])
    model.ir_version = 8
    onnx.checker.check_model(model)
    onnx.save(model, output_path)
    print(f"  Built: {output_path}  (2 nodes → expect 0 after pass)")


def build_mergeable_chain(output_path="tests/toy_models/transpose_mergeable.onnx"):
    """
    Two Transposes that merge into one (compose to non-identity).
        input  (1,4,8,8)
        → Transpose(perm=[0,2,1,3])
        → Transpose(perm=[0,1,3,2])
        → output
    Composed perm: [0,3,1,2]  → not identity, 2 nodes become 1
    Expected: 2 nodes → 1 node
    """
    X = helper.make_tensor_value_info("X", TensorProto.FLOAT, [1, 4, 8, 8])
    Y = helper.make_tensor_value_info("Y", TensorProto.FLOAT, [1, 8, 4, 8])

    t1 = helper.make_node("Transpose", ["X"],   ["mid"], perm=[0, 2, 1, 3], name="T1")
    t2 = helper.make_node("Transpose", ["mid"], ["Y"],   perm=[0, 1, 3, 2], name="T2")

    graph = helper.make_graph([t1, t2], "mergeable_chain", [X], [Y])
    model = helper.make_model(graph, opset_imports=[helper.make_opsetid("", 13)])
    model.ir_version = 8
    onnx.checker.check_model(model)
    onnx.save(model, output_path)
    print(f"  Built: {output_path}  (2 nodes → expect 1 after pass)")


def build_clean_model(output_path="tests/toy_models/transpose_clean.onnx"):
    """
    Single Transpose — nothing to eliminate.
    Pass should do nothing.
    Expected: 1 node → 1 node
    """
    X = helper.make_tensor_value_info("X", TensorProto.FLOAT, [1, 3, 4, 4])
    Y = helper.make_tensor_value_info("Y", TensorProto.FLOAT, [1, 4, 4, 3])

    t1 = helper.make_node("Transpose", ["X"], ["Y"], perm=[0, 2, 3, 1], name="T1")

    graph = helper.make_graph([t1], "clean_model", [X], [Y])
    model = helper.make_model(graph, opset_imports=[helper.make_opsetid("", 13)])
    model.ir_version = 8
    onnx.checker.check_model(model)
    onnx.save(model, output_path)
    print(f"  Built: {output_path}  (1 node → expect 1 after pass)")


def build_triple_chain(output_path="tests/toy_models/transpose_triple.onnx"):
    """
    Three consecutive Transposes — first two cancel, third survives.
        T1: [0,2,3,1]
        T2: [0,3,1,2]  ← cancels T1
        T3: [0,2,3,1]  ← survives alone
    Expected: 3 nodes → 1 node
    """
    X  = helper.make_tensor_value_info("X",  TensorProto.FLOAT, [1, 3, 4, 4])
    Y  = helper.make_tensor_value_info("Y",  TensorProto.FLOAT, [1, 4, 4, 3])

    t1 = helper.make_node("Transpose", ["X"],    ["mid1"], perm=[0, 2, 3, 1], name="T1")
    t2 = helper.make_node("Transpose", ["mid1"], ["mid2"], perm=[0, 3, 1, 2], name="T2")
    t3 = helper.make_node("Transpose", ["mid2"], ["Y"],    perm=[0, 2, 3, 1], name="T3")

    graph = helper.make_graph([t1, t2, t3], "triple_chain", [X], [Y])
    model = helper.make_model(graph, opset_imports=[helper.make_opsetid("", 13)])
    model.ir_version = 8
    onnx.checker.check_model(model)
    onnx.save(model, output_path)
    print(f"  Built: {output_path}  (3 nodes → expect 1 after pass)")


if __name__ == "__main__":
    os.makedirs("tests/toy_models", exist_ok=True)
    print("Building toy models for M4...\n")
    build_cancelling_pair()
    build_mergeable_chain()
    build_clean_model()
    build_triple_chain()
    print("\nDone. All models saved to tests/toy_models/")
```

---

## Test File: `tests/test_transposes.py`

Precise assertions — not just "verify passed" but exact node counts and correct composed perms.

```python
"""
Tests for eliminate_redundant_transposes.
Uses synthetic toy models with known expected outcomes.
Run: python tests/test_transposes.py
"""
import onnx
from verify import verify
from passes.eliminate_redundant_transposes import EliminateRedundantTransposes


def _run_pass(model_path):
    original  = onnx.load(model_path)
    model     = onnx.load(model_path)
    optimized = EliminateRedundantTransposes().run(model)
    report    = verify(original, optimized, n_samples=10)
    onnx.checker.check_model(optimized)
    return original, optimized, report


def test_cancelling_pair():
    orig, opt, report = _run_pass("tests/toy_models/transpose_cancelling.onnx")
    assert len(orig.graph.node) == 2, "Expected 2 nodes before"
    assert len(opt.graph.node) == 0, f"Expected 0 nodes after, got {len(opt.graph.node)}"
    assert report.passed and report.max_diff < 1e-5
    print(f"  ✓ cancelling_pair:  2 → 0 nodes | max_diff={report.max_diff:.2e}")


def test_mergeable_chain():
    orig, opt, report = _run_pass("tests/toy_models/transpose_mergeable.onnx")
    assert len(orig.graph.node) == 2
    assert len(opt.graph.node) == 1, f"Expected 1 node after, got {len(opt.graph.node)}"

    surviving = opt.graph.node[0]
    perm = list(surviving.attribute[0].ints)
    assert perm == [0, 3, 1, 2], f"Expected composed perm [0,3,1,2], got {perm}"

    assert report.passed and report.max_diff < 1e-5
    print(f"  ✓ mergeable_chain:  2 → 1 node | perm={perm} | max_diff={report.max_diff:.2e}")


def test_clean_model():
    orig, opt, report = _run_pass("tests/toy_models/transpose_clean.onnx")
    assert len(orig.graph.node) == 1
    assert len(opt.graph.node) == 1, "Clean model should be untouched"
    assert report.passed
    print(f"  ✓ clean_model:      1 → 1 node (untouched) | max_diff={report.max_diff:.2e}")


def test_triple_chain():
    orig, opt, report = _run_pass("tests/toy_models/transpose_triple.onnx")
    assert len(orig.graph.node) == 3
    assert len(opt.graph.node) == 1, f"Expected 1 node after, got {len(opt.graph.node)}"
    assert report.passed and report.max_diff < 1e-5
    print(f"  ✓ triple_chain:     3 → 1 node | max_diff={report.max_diff:.2e}")


def test_mobilenetv2():
    """Integration check — pass runs cleanly on a real model."""
    orig, opt, report = _run_pass("mobilenetv2-12.onnx")
    assert report.passed
    nodes_before = len(orig.graph.node)
    nodes_after  = len(opt.graph.node)
    print(f"  ✓ mobilenetv2:      {nodes_before} → {nodes_after} nodes | max_diff={report.max_diff:.2e}")


if __name__ == "__main__":
    import os
    if not os.path.exists("tests/toy_models/transpose_cancelling.onnx"):
        print("Building toy models first...")
        exec(open("tests/toy_models/build_transpose_model.py").read())

    print("\nRunning M4 tests...\n")
    test_cancelling_pair()
    test_mergeable_chain()
    test_clean_model()
    test_triple_chain()
    test_mobilenetv2()
    print("\n✅ All M4 tests passed.")
```

---

## `tests/toy_models/__init__.py`

```python
# toy_models — synthetic dirty ONNX models for pass-level testing
```

---

## Update `passes/__init__.py`

```python
from passes.eliminate_dead_nodes import EliminateDeadNodes
from passes.eliminate_identity_ops import EliminateIdentityOps
from passes.eliminate_unused_initializers import EliminateUnusedInitializers
from passes.eliminate_duplicate_constants import EliminateDuplicateConstants
from passes.eliminate_redundant_transposes import EliminateRedundantTransposes
```

## Update `optimizer.py`

```python
from passes.eliminate_redundant_transposes import EliminateRedundantTransposes

registered_passes = [
    EliminateDeadNodes(),
    EliminateIdentityOps(),
    EliminateUnusedInitializers(),
    EliminateDuplicateConstants(),
    EliminateRedundantTransposes(),
]
```

---

## Run Order

```bash
# Step 1 — build the toy models
python tests/toy_models/build_transpose_model.py

# Step 2 — run targeted tests (precise assertions)
python tests/test_transposes.py

# Step 3 — full optimizer integration check
python optimizer.py mobilenetv2-12.onnx mobilenetv2-12-m4.onnx

# Step 4 — standalone verify
python verify.py mobilenetv2-12.onnx mobilenetv2-12-m4.onnx
```

**Expected test output:**
```
Running M4 tests...

  ✓ cancelling_pair:  2 → 0 nodes | max_diff=0.00e+00
  ✓ mergeable_chain:  2 → 1 node  | perm=[0, 3, 1, 2] | max_diff=0.00e+00
  ✓ clean_model:      1 → 1 node (untouched) | max_diff=0.00e+00
  ✓ triple_chain:     3 → 1 node  | max_diff=0.00e+00
  ✓ mobilenetv2:      105 → 105 nodes | max_diff=0.00e+00

✅ All M4 tests passed.
```

---

## Definition of Done

- [ ] `tests/toy_models/__init__.py` created
- [ ] `build_transpose_model.py` generates all 4 dirty models without errors
- [ ] All 4 `.onnx` toy files pass `onnx.checker.check_model()`
- [ ] `eliminate_redundant_transposes.py` implemented
- [ ] `passes/__init__.py` updated
- [ ] `optimizer.py` updated with pass registered
- [ ] `test_cancelling_pair` → 2 nodes become 0 ✓
- [ ] `test_mergeable_chain` → 2 nodes become 1, correct composed perm asserted ✓
- [ ] `test_clean_model` → 1 node stays 1 (untouched) ✓
- [ ] `test_triple_chain` → 3 nodes become 1 ✓
- [ ] All tests pass with max_diff < 1e-5
- [ ] Full optimizer run on MobileNetV2 still clean

---

## Known Gotchas

**While loop for chains** — the pass runs `_run_one_pass` in a while loop until no more
changes occur. A single scan only collapses one pair at a time. The triple chain test
will catch this if you forget the loop.

**Graph output protection** — if a Transpose's output is directly a graph output, you
cannot remove it even if it cancels with the next node. The code guards for this.

**Mergeable chain output shape** — when building the toy model, make sure the declared
output shape in `make_tensor_value_info` matches what the composed Transpose actually
produces. Wrong shapes will fail `onnx.checker`. Easiest way: compute the composed perm
first, then figure out the output shape from it.

**Node ordering after rebuild** — after deleting and re-adding nodes, the order in the
proto changes. ONNX Runtime handles any order, but if `onnx.checker` complains, topological
sort the node list before saving.

---

## Toy Model Pattern — Template for Every Pass from Here

```
tests/
└── toy_models/
    ├── build_transpose_model.py     ← M4  (done here)
    ├── build_constants_model.py     ← M5  fold_constants
    ├── build_shape_chain_model.py   ← M6  simplify_shape_chains
    ├── build_conv_bn_model.py       ← M7  fuse_conv_batchnorm
    ├── build_conv_relu_model.py     ← M8  fuse_conv_relu
    └── build_attention_model.py     ← M9  cleanup_attention
```

Each builder follows this pattern:
- `build_[dirty_variant]()` — has the problem, pass must fire
- `build_[clean_variant]()` — no problem, pass must do nothing (regression guard)
- `build_[edge_case]()` — catches the specific gotcha for that pass

---

## Next: M5 — fold_constants

Once M4 is green → `micro_plan_M5.md`.

This is the most impactful single pass in the pipeline. Any subgraph where every input is
a constant gets pre-computed by ONNX Runtime and replaced with a single Constant node.
Shape manipulation chains, positional encodings, mask computations — all collapse.

The M5 toy model will have a hand-crafted constant subgraph (e.g. Add of two constant
tensors) where we can assert the subgraph collapses to exactly one node containing the
pre-computed result value.
